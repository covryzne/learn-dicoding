{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "GHCGNTyrM5fS",
        "outputId": "7ca08e39-27c1-4fb6-82ab-cb426dd815e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order_ID</th>\n",
              "      <th>Customer_ID</th>\n",
              "      <th>Product</th>\n",
              "      <th>Unit_Price</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Discount</th>\n",
              "      <th>Total_Price</th>\n",
              "      <th>Region</th>\n",
              "      <th>Order_Date</th>\n",
              "      <th>Customer_Type_B2C</th>\n",
              "      <th>Category_Juices</th>\n",
              "      <th>Category_Soft Drinks</th>\n",
              "      <th>Category_Water</th>\n",
              "      <th>Product_FreqEnc</th>\n",
              "      <th>Region_FreqEnc</th>\n",
              "      <th>Quantity_Bin</th>\n",
              "      <th>TotalPrice_Bin</th>\n",
              "      <th>Cluster</th>\n",
              "      <th>Cluster_PCA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ORD1663596</td>\n",
              "      <td>CUS5073</td>\n",
              "      <td>Hohes C Orange</td>\n",
              "      <td>1.87</td>\n",
              "      <td>74</td>\n",
              "      <td>0.10</td>\n",
              "      <td>124.54</td>\n",
              "      <td>Niedersachsen</td>\n",
              "      <td>2023-11-29</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.03675</td>\n",
              "      <td>0.06275</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ORD1999010</td>\n",
              "      <td>CUS141</td>\n",
              "      <td>Fritz-Kola</td>\n",
              "      <td>1.87</td>\n",
              "      <td>18</td>\n",
              "      <td>0.05</td>\n",
              "      <td>31.98</td>\n",
              "      <td>Bremen</td>\n",
              "      <td>2021-05-13</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.02375</td>\n",
              "      <td>0.06875</td>\n",
              "      <td>High</td>\n",
              "      <td>Medium</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ORD347756</td>\n",
              "      <td>CUS562</td>\n",
              "      <td>Merlot</td>\n",
              "      <td>12.04</td>\n",
              "      <td>71</td>\n",
              "      <td>0.15</td>\n",
              "      <td>726.61</td>\n",
              "      <td>Thüringen</td>\n",
              "      <td>2021-04-21</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.01075</td>\n",
              "      <td>0.05875</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ORD600360</td>\n",
              "      <td>CUS7718</td>\n",
              "      <td>Moët &amp; Chandon</td>\n",
              "      <td>64.91</td>\n",
              "      <td>91</td>\n",
              "      <td>0.10</td>\n",
              "      <td>5316.13</td>\n",
              "      <td>Hamburg</td>\n",
              "      <td>2021-08-23</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.01175</td>\n",
              "      <td>0.06725</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ORD2300591</td>\n",
              "      <td>CUS6160</td>\n",
              "      <td>Granini Apple</td>\n",
              "      <td>1.64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.56</td>\n",
              "      <td>Sachsen</td>\n",
              "      <td>2022-10-16</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.03575</td>\n",
              "      <td>0.06425</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Order_ID Customer_ID         Product  Unit_Price  Quantity  Discount  \\\n",
              "0  ORD1663596     CUS5073  Hohes C Orange        1.87        74      0.10   \n",
              "1  ORD1999010      CUS141      Fritz-Kola        1.87        18      0.05   \n",
              "2   ORD347756      CUS562          Merlot       12.04        71      0.15   \n",
              "3   ORD600360     CUS7718  Moët & Chandon       64.91        91      0.10   \n",
              "4  ORD2300591     CUS6160   Granini Apple        1.64         4      0.00   \n",
              "\n",
              "   Total_Price         Region  Order_Date  Customer_Type_B2C  Category_Juices  \\\n",
              "0       124.54  Niedersachsen  2023-11-29              False             True   \n",
              "1        31.98         Bremen  2021-05-13              False            False   \n",
              "2       726.61      Thüringen  2021-04-21              False            False   \n",
              "3      5316.13        Hamburg  2021-08-23              False            False   \n",
              "4         6.56        Sachsen  2022-10-16               True             True   \n",
              "\n",
              "   Category_Soft Drinks  Category_Water  Product_FreqEnc  Region_FreqEnc  \\\n",
              "0                 False           False          0.03675         0.06275   \n",
              "1                  True           False          0.02375         0.06875   \n",
              "2                 False           False          0.01075         0.05875   \n",
              "3                 False           False          0.01175         0.06725   \n",
              "4                 False           False          0.03575         0.06425   \n",
              "\n",
              "  Quantity_Bin TotalPrice_Bin  Cluster  Cluster_PCA  \n",
              "0         High           High        0            0  \n",
              "1         High         Medium        1            1  \n",
              "2         High           High        0            0  \n",
              "3         High           High        2            2  \n",
              "4          Low            Low        1            1  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('Dataset_inisiasi.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6U89rZvyzrP",
        "outputId": "d6898c10-4453-4310-a45e-fd9f3e96f2ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4000 entries, 0 to 3999\n",
            "Data columns (total 19 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Order_ID              4000 non-null   object \n",
            " 1   Customer_ID           4000 non-null   object \n",
            " 2   Product               4000 non-null   object \n",
            " 3   Unit_Price            4000 non-null   float64\n",
            " 4   Quantity              4000 non-null   int64  \n",
            " 5   Discount              4000 non-null   float64\n",
            " 6   Total_Price           4000 non-null   float64\n",
            " 7   Region                4000 non-null   object \n",
            " 8   Order_Date            4000 non-null   object \n",
            " 9   Customer_Type_B2C     4000 non-null   bool   \n",
            " 10  Category_Juices       4000 non-null   bool   \n",
            " 11  Category_Soft Drinks  4000 non-null   bool   \n",
            " 12  Category_Water        4000 non-null   bool   \n",
            " 13  Product_FreqEnc       4000 non-null   float64\n",
            " 14  Region_FreqEnc        4000 non-null   float64\n",
            " 15  Quantity_Bin          4000 non-null   object \n",
            " 16  TotalPrice_Bin        4000 non-null   object \n",
            " 17  Cluster               4000 non-null   int64  \n",
            " 18  Cluster_PCA           4000 non-null   int64  \n",
            "dtypes: bool(4), float64(5), int64(3), object(7)\n",
            "memory usage: 484.5+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      },
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OubAW-7ONKVj",
        "outputId": "40248a99-7b27-4af4-d41d-f3f9edd5957a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Latih: (3200, 15), Data Uji: (800, 15)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Memisahkan fitur dan target\n",
        "X = df.drop(columns=['Cluster', 'Order_ID', 'Customer_ID', 'Order_Date'])  # Menghilangkan kolom non-numerik dan 'Cluster'\n",
        "y = df['Cluster']  # Targetnya adalah kolom 'Cluster'\n",
        "\n",
        "# Membagi data menjadi data latih (80%) dan data uji (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tampilkan bentuk data latih dan uji\n",
        "print(f\"Data Latih: {X_train.shape}, Data Uji: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nekB0LhyzrQ",
        "outputId": "bd3e360d-9bc6-48c1-f0c2-a38cda44dd87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Latih: (3200, 8433), Data Uji: (800, 8433)\n"
          ]
        }
      ],
      "source": [
        "# Mengonversi kolom kategorikal menjadi variabel dummy (One-Hot Encoding)\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)  # drop_first=True untuk menghindari dummy variable trap\n",
        "\n",
        "# Memisahkan fitur dan target lagi setelah encoding\n",
        "X = df_encoded.drop(columns=['Cluster'])  # Menghilangkan kolom target 'Cluster'\n",
        "y = df_encoded['Cluster']  # Targetnya adalah kolom 'Cluster'\n",
        "\n",
        "# Membagi data menjadi data latih (80%) dan data uji (20%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tampilkan bentuk data latih dan uji\n",
        "print(f\"Data Latih: {X_train.shape}, Data Uji: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ned1pL9zMmBK"
      },
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAWzPOE4Nkti"
      },
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YmeSlykyzrR"
      },
      "source": [
        "### **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KXrmWCuyzrR",
        "outputId": "f1f2aa48-ab7a-4756-e0a8-f13180aacd7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model selesai\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)  # Pilih jumlah k (misal: k=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "print(\"Training model selesai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm4-4NDMyzrR"
      },
      "source": [
        "### **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhXCR7EQyzrR",
        "outputId": "ccadf25a-4f10-41ba-c26e-7cca15510eca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model selesai\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "print(\"Training model selesai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seYoHNY3XU1y"
      },
      "source": [
        "**`Algoritma KNN (K-Nearest Neighbors)`** <br>\n",
        "Pada dasarnya, algoritma ini bekerja dengan mencari k data terdekat (tetangga terdekat) di ruang fitur dan menentukan kelas berdasarkan mayoritas kelas tetangga tersebut. KNN adalah algoritma non-parametrik yang sederhana, tidak memerlukan asumsi tentang distribusi data, dan sangat bergantung pada jarak antar data.\n",
        "\n",
        "**`Penerapan KNN dalam Proyek Ini`** <br>\n",
        "Pada proyek ini, algoritma KNN digunakan untuk melakukan klasifikasi data dengan tujuan memprediksi kelas atau label pada dataset yang digunakan. Secara spesifik, model KNN diterapkan pada dataset yang memiliki banyak fitur dan label yang berbeda, di mana model ini akan menghitung jarak antara data uji dan tetangga terdekat dalam data latih untuk memprediksi kelas yang paling sering muncul di antara tetangga tersebut.\n",
        "\n",
        "**`Algoritma Random Forest Tree`** <br>\n",
        "Algoritma ensemble yang menggabungkan banyak decision trees untuk meningkatkan akurasi klasifikasi. Setiap pohon keputusan pada Random Forest dibuat dengan memilih subset acak dari data dan fitur, yang mengurangi kemungkinan overfitting dan meningkatkan generalisasi model. Random Forest adalah algoritma yang sangat kuat dan sering digunakan untuk klasifikasi dan regresi, terutama dalam dataset yang besar dan kompleks.\n",
        "\n",
        "**`Penerapan Random Forest dalam Proyek Ini`** <br>\n",
        "Pada proyek ini, Random Forest diterapkan untuk melakukan klasifikasi pada data yang serupa dengan KNN, tetapi dengan pendekatan yang berbeda. Random Forest membangun banyak pohon keputusan yang saling beragam dan menghasilkan prediksi berdasarkan hasil mayoritas dari semua pohon yang ada. Setiap pohon dibangun menggunakan subset acak dari data dan fitur, sehingga meningkatkan keberagaman antar pohon dan mengurangi overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergzChZFEL-O"
      },
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOm68u-7NpLT"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoWDCF8tyzrS"
      },
      "source": [
        "### **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtHT6di0yzrS",
        "outputId": "821ac86b-18ab-45da-ef5d-9ccb9c02ad59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy KNN: 0.9563\n",
            "Classification Report KNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.87      0.90       175\n",
            "           1       0.97      0.98      0.97       571\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       0.93      0.95      0.94        42\n",
            "\n",
            "    accuracy                           0.96       800\n",
            "   macro avg       0.95      0.95      0.95       800\n",
            "weighted avg       0.96      0.96      0.96       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"Accuracy KNN: {accuracy_knn:.4f}\")\n",
        "print(\"Classification Report KNN:\")\n",
        "print(classification_report(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVPIP1EO9VJ5",
        "outputId": "f445ed85-6799-4d87-963c-7d520b814bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN Confusion Matrix:\n",
            "[[153  19   0   3]\n",
            " [ 11 560   0   0]\n",
            " [  0   0  12   0]\n",
            " [  2   0   0  40]]\n"
          ]
        }
      ],
      "source": [
        "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "print(\"KNN Confusion Matrix:\")\n",
        "print(cm_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOmW8zEZyzrS"
      },
      "source": [
        "### **Random Forest Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ8MMtAZyzrS",
        "outputId": "de2b6ecd-3d64-45cf-bc52-104a4c227291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Random Forest: 0.9988\n",
            "Classification Report Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       175\n",
            "           1       1.00      1.00      1.00       571\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       1.00      0.98      0.99        42\n",
            "\n",
            "    accuracy                           1.00       800\n",
            "   macro avg       1.00      0.99      1.00       800\n",
            "weighted avg       1.00      1.00      1.00       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_classification_report = classification_report(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Accuracy Random Forest: {rf_accuracy:.4f}\")\n",
        "print(f\"Classification Report Random Forest:\\n{rf_classification_report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo0CEnWO9oAN",
        "outputId": "41d5e09c-68aa-451a-87bd-180c0155713f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Random Forest Confusion Matrix:\n",
            "[[175   0   0   0]\n",
            " [  0 571   0   0]\n",
            " [  0   0  12   0]\n",
            " [  1   0   0  41]]\n"
          ]
        }
      ],
      "source": [
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"\\nRandom Forest Confusion Matrix:\")\n",
        "print(cm_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4_9OwrsXZlz"
      },
      "source": [
        "Berikut adalah perbedaan dua algoritma klasifikasi yang digunakan, yaitu K-Nearest Neighbors (KNN) dan Random Forest:\n",
        "\n",
        "1. `K-Nearest Neighbors (KNN)`: <br>\n",
        "Akurasi model KNN mencapai **`95.63%`**, yang menunjukkan bahwa model ini cukup baik dalam memprediksi cluster secara keseluruhan.\n",
        "\n",
        "  `Report`\n",
        "  - Precision, recall, dan F1-score sangat baik untuk cluster 1 (nilai tertinggi, 97-98%) yang merupakan cluster mayoritas.\n",
        "  - cluster 0 (dengan support 175) memiliki precision yang sedikit lebih rendah (92%) dan recall yang juga rendah (87%), mengindikasikan bahwa model KNN sedikit kurang efektif dalam mengidentifikasi cluster 0.\n",
        "  - cluster 2 (dengan support 12) mendapatkan hasil yang sangat baik, dengan recall dan precision masing-masing 100%.\n",
        "  - cluster 3 (dengan support 42) juga menunjukkan hasil yang baik, meskipun ada sedikit penurunan pada recall (95%) dibandingkan cluster lainnya.\n",
        "\n",
        "  `Confusion Matrix`\n",
        "  - cluster 0 memiliki beberapa prediksi yang salah, yaitu 19 prediksi salah cluster 1 dan 3 prediksi salah cluster 3.\n",
        "  - cluster 1 menunjukkan sedikit kesalahan, dengan 11 prediksi salah pada cluster 0.\n",
        "  - cluster 2 berhasil diprediksi dengan sempurna tanpa kesalahan.\n",
        "  - cluster 3 juga menunjukkan hasil yang baik dengan hanya 2 kesalahan pada cluster 0.\n",
        "\n",
        "2. `Random Forest:` <br>\n",
        "Akurasi model Random Forest mencapai 99.88%, yang sangat tinggi dan menunjukkan performa model yang hampir sempurna.\n",
        "\n",
        "  `Report`\n",
        "  - Precision, recall, dan F1-score untuk semua cluster sangat tinggi (di atas 99%) dengan Random Forest menunjukkan performa yang hampir sempurna pada setiap cluster.\n",
        "  - Untuk cluster 0 dan 1, model ini mencapai akurasi 100% pada precision dan recall.\n",
        "  - cluster 2 juga mendapat hasil yang sangat baik dengan 100% recall dan precision.\n",
        "  - cluster 3 hanya memiliki sedikit penurunan pada recall (98%), tetapi tetap menunjukkan performa yang sangat baik secara keseluruhan.\n",
        "\n",
        "  `Confusion Matrix`\n",
        "  - Semua cluster teridentifikasi dengan sangat baik tanpa adanya kesalahan pada cluster mayoritas (cluster 1 dan 0).\n",
        "  - cluster 2 dan 3 juga terprediksi dengan sangat akurat, dengan hanya satu kesalahan pada cluster 3.\n",
        "  - Tidak ada kesalahan besar dalam prediksi pada Random Forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph9yIYDXEPuB"
      },
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bikx3LINv5e"
      },
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nYjk-P_1BsI"
      },
      "source": [
        "### **Hyperparameter Tuning Random Forest Tree menggunakan RandomizedSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(50, 201, 50),  # Jumlah pohon (forest)\n",
        "    'max_features': ['sqrt', 'sqrt', 'log2'],  # Fitur yang dipertimbangkan untuk split\n",
        "    'max_depth': np.arange(10, 101, 10),  # Kedalaman maksimal pohon\n",
        "    'min_samples_split': np.arange(2, 11, 1),  # Minimum sampel untuk melakukan split\n",
        "    'min_samples_leaf': np.arange(1, 11, 1),  # Minimum sampel di daun pohon\n",
        "    'bootstrap': [True, False]  # Bootstrap sampling\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=10, cv=5, verbose=1, random_state=42, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBs2SzIG3pSR"
      },
      "source": [
        "### **Hyperparameter Tuning KNN menggunakan RandomizedSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XfVGOqbf4v7n"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "param_dist_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 13],  # Jumlah tetangga yang digunakan\n",
        "    'weights': ['uniform', 'distance'],   # Jenis bobot (uniform atau distance)\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algoritma yang digunakan\n",
        "    'leaf_size': [20, 30, 40, 50],        # Ukuran daun untuk algoritma Ball Tree dan KD Tree\n",
        "    'p': [2]                          # Parameter untuk metrik Minkowski (1=Manhattan, 2=Euclidean)\n",
        "}\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "random_search_knn = RandomizedSearchCV(knn_model, param_distributions=param_dist_knn,\n",
        "                                       n_iter=3, cv=3, verbose=1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7pqlEPEYzI"
      },
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feaPESoeN0zz"
      },
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnNtyGeD3WcG"
      },
      "source": [
        "### **Evaluasi Hyperparameter Tuning Random Forest menggunakan RandomizedSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXZRvEeNMb1",
        "outputId": "bd07772a-0133-4864-e50a-e935c736c9f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Best Parameters: {'n_estimators': np.int64(200), 'min_samples_split': np.int64(7), 'min_samples_leaf': np.int64(1), 'max_features': 'sqrt', 'max_depth': np.int64(40), 'bootstrap': False}\n",
            "Accuracy Random Forest (Tuning): 0.9988\n",
            "Classification Report Random Forest (Tuning):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       175\n",
            "           1       1.00      1.00      1.00       571\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       1.00      0.98      0.99        42\n",
            "\n",
            "    accuracy                           1.00       800\n",
            "   macro avg       1.00      0.99      1.00       800\n",
            "weighted avg       1.00      1.00      1.00       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "\n",
        "best_rf_model = random_search.best_estimator_\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
        "print(f\"Accuracy Random Forest (Tuning): {accuracy_best_rf:.4f}\")\n",
        "print(\"Classification Report Random Forest (Tuning):\")\n",
        "print(classification_report(y_test, y_pred_best_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqJ6ADrZ4c22"
      },
      "source": [
        "### **Evaluasi Hyperparameter Tuning KNN menggunakan RandomizedSearchCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itcwkt0o5L--",
        "outputId": "edeb130f-4fd0-4bb5-d1b9-019dec502c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "Best Parameters for KNN: {'weights': 'distance', 'p': 2, 'n_neighbors': 11, 'leaf_size': 50, 'algorithm': 'auto'}\n",
            "Accuracy KNN (Tuning): 0.9550\n",
            "Classification Report KNN (Tuning):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.86      0.90       175\n",
            "           1       0.96      0.98      0.97       571\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       0.87      0.98      0.92        42\n",
            "\n",
            "    accuracy                           0.95       800\n",
            "   macro avg       0.94      0.95      0.95       800\n",
            "weighted avg       0.96      0.95      0.95       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "random_search_knn.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters for KNN: {random_search_knn.best_params_}\")\n",
        "\n",
        "best_knn_model = random_search_knn.best_estimator_\n",
        "y_pred_best_knn = best_knn_model.predict(X_test)\n",
        "\n",
        "accuracy_best_knn = accuracy_score(y_test, y_pred_best_knn)\n",
        "print(f\"Accuracy KNN (Tuning): {accuracy_best_knn:.4f}\")\n",
        "print(\"Classification Report KNN (Tuning):\")\n",
        "print(classification_report(y_test, y_pred_best_knn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      },
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "\n",
        "1. Perbanbandingan hasil evaluasi sebelum dan setelah tuning.\n",
        "\n",
        "  `Random Forest Tree`\n",
        "  - Setelah tuning, akurasi meningkat sedikit (dari 99.75% menjadi 99.88%), meskipun perubahan ini tidak terlalu signifikan, namun menunjukkan bahwa tuning hyperparameter memberikan sedikit perbaikan.\n",
        "  - Precision dan Recall tetap sangat baik dan stabil untuk semua cluster, dengan sedikit peningkatan di beberapa metrik.\n",
        "  - F1-Score tetap sangat baik, dengan nilai 1.00 untuk tiga cluster pertama dan 0.99 untuk cluster 3, yang menunjukkan model sudah sangat optimal setelah tuning.\n",
        "\n",
        "  `KNN`\n",
        "  - Akurasi tetap sama setelah tuning (95.50%), yang menunjukkan bahwa hyperparameter tuning pada KNN tidak memberikan perubahan besar pada akurasi secara keseluruhan.\n",
        "  - Precision dan Recall untuk cluster 0, meskipun cukup baik, masih menunjukkan adanya kelemahan, terutama pada cluster 0 di bagian recall (0.86).\n",
        "  - F1-Score juga tetap sama, dengan cluster 0 masih menjadi tantangan bagi model.\n",
        "  - Meskipun tuning menghasilkan beberapa perubahan dalam parameter, model KNN tidak menunjukkan peningkatan signifikan dibandingkan sebelum tuning, terutama pada cluster 0.\n",
        "\n",
        "  `Kesimpulan`\n",
        "  - Random Forest menunjukkan peningkatan sedikit dalam akurasi setelah tuning, tetapi perubahan pada metrik lain relatif kecil. Model ini sangat efektif setelah tuning, dengan hasil precision, recall, dan f1-score hampir sempurna.\n",
        "  - KNN, meskipun mengalami tuning, akurasi tidak berubah, dan model masih kesulitan pada cluster 0, dengan precision dan recall yang lebih rendah dibandingkan cluster lainnya. Tuning tidak memberikan dampak besar pada performa KNN.\n",
        "\n",
        "\n",
        "2. Identifikasi kelemahan model:\n",
        "\n",
        "  `Random Forest`\n",
        "  - Meskipun precision untuk cluster 3 sangat tinggi (1.00), recall untuk cluster 3 sedikit lebih rendah (0.98). Ini menunjukkan bahwa meskipun model dapat mengenali sebagian besar instance cluster 3 dengan sangat baik, ada sedikit kelemahan dalam mengidentifikasi beberapa data cluster 3 yang mungkin lebih sulit atau ambigu.\n",
        "  - cluster 2 (yang memiliki hanya 12 data) memiliki hasil yang sangat baik, namun ini tidak sepenuhnya menggambarkan bahwa model tersebut akan efektif pada dataset yang lebih besar atau lebih tidak seimbang. <br>\n",
        "\n",
        "  `Apakah Model Mengalami Overfitting atau Underfitting?`\n",
        "  - Random Forest tidak menunjukkan tanda-tanda overfitting. Akurasi tinggi pada data uji (99.88%) menunjukkan bahwa model dapat memgeneralisasi dengan baik dan tidak hanya menghafal data latih. Selain itu, model ini menggunakan cross-validation yang menunjukkan bahwa hasilnya stabil di berbagai subset data.\n",
        "  - Random Forest tampaknya tidak mengalami underfitting karena akurasi dan metrik evaluasi lainnya sangat baik. Model ini cukup kompleks dan memiliki kemampuan untuk menangkap pola dengan baik.\n",
        "\n",
        "  `Kesimpulan` <br>\n",
        "  Model Random Forest secara keseluruhan menunjukkan performa yang sangat baik dengan sedikit kelemahan pada cluster 3 dalam hal recall. Model ini tidak menunjukkan overfitting atau underfitting.\n",
        "\n",
        "  `KNN (K-Nearest Neighbors)`\n",
        "  - Pada model KNN sebelum tuning, recall untuk cluster 0 sangat rendah (0.86), yang menunjukkan bahwa model kesulitan dalam mengidentifikasi instance dari cluster 0. Ini berhubungan dengan precision yang lebih rendah pada cluster 0 (0.94) dibandingkan dengan cluster lainnya.\n",
        "  - Hal ini mungkin terjadi karena cluster 0 memiliki jumlah data yang cukup banyak, dan mungkin terdapat lebih banyak variasi dalam data cluster 0 yang sulit untuk dipelajari oleh model KNN dengan parameter yang ada sebelum tuning.\n",
        "  - Recall untuk cluster 3 tetap sangat baik (0.98), tetapi precision untuk cluster 3 lebih rendah dibandingkan dengan cluster 1 dan cluster 2 (0.87). cluster 3 menjadi tantangan yang lebih besar untuk KNN, mungkin karena distribusi data yang tidak seimbang atau fitur yang kurang informatif untuk membedakan cluster ini dari cluster lainnya.\n",
        "\n",
        "  `Apakah Model Mengalami Overfitting atau Underfitting?`\n",
        "  - Model KNN menunjukkan kemungkinan underfitting lebih daripada overfitting. Meskipun KNN sudah dioptimalkan dengan hyperparameter tuning, hasil akurasi tetap stabil dan precision serta recall untuk beberapa cluster (terutama cluster 0) menunjukkan bahwa model masih tidak dapat sepenuhnya menangani kompleksitas dataset.\n",
        "  - KNN cenderung underfitting karena meskipun akurasi cukup tinggi (95.50%), ada kelemahan yang signifikan pada beberapa cluster, terutama pada recall untuk cluster 0. Ini menunjukkan bahwa model tidak cukup kompleks atau tidak cukup baik dalam menangkap variasi data pada cluster tertentu.\n",
        "\n",
        "  `Kesimpulan` <br>\n",
        "  Model KNN menunjukkan underfitting, dengan kelemahan terbesar pada cluster 0 dalam hal recall dan precision. Meskipun tuning dapat memperbaiki beberapa aspek, model ini masih kesulitan dalam menangani cluster dengan variasi data yang lebih besar, seperti cluster 0.\n",
        "\n",
        "3. Rekomendasi Tindakan Lanjutan\n",
        "\n",
        "  - Tambahkan lebih banyak data, terutama untuk kelas minoritas (seperti kelas 3), agar model lebih efektif dalam mengenali pola pada kelas tersebut.\n",
        "  - Jika hasil belum memuaskan, pertimbangkan untuk mencoba algoritma lain seperti Support Vector Machines (SVM) atau XGBoost yang sering memberikan hasil lebih baik pada dataset besar dan kompleks.\n",
        "\n",
        "  - Lakukan tuning parameter lebih mendalam menggunakan Grid Search atau metode optimasi lainnya untuk menemukan kombinasi parameter yang lebih optimal.\n",
        "\n",
        "  - Gunakan teknik seperti SMOTE untuk oversampling kelas minoritas atau sesuaikan class weights untuk memberikan perhatian lebih pada kelas yang kurang terwakili.\n",
        "\n",
        "  - Gunakan lebih banyak fold (misalnya, 10-fold cross-validation) untuk mendapatkan evaluasi yang lebih stabil dan akurat."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
