# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12D1gOc6N1dlX-t4iyOlWeu1NqFYvcQIz

# Proyek Klasifikasi Gambar: Flower Image Classification
- **Nama:** Shendi Teuku Maulana Efendi
- **Email:** shendyteuku2@gmail.com
- **ID Dicoding:** shendyeff

## Import Semua Packages/Library yang Digunakan

## Import Semua Packages/Library yang Digunakan <br>
Menghindari session crash saat menyimpan model TFLite Karena defaultnya di google collab sudah terinstall tensorflow, dan tensorflow itu versi 2.15.0, sedangkan yang kamu install versi terbaru (jadi ketika menginstall package lagi bertubrukan dengan versi lama)  yang menyebabkan runtime error (restart).
"""

!pip install tensorflowjs

!pip install tensorflow==2.15.0

# Import standard libraries
import os
import random
import shutil
import pathlib
import glob
import warnings
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image
import cv2
import gdown

# Suppress warnings
warnings.filterwarnings('ignore')

# Import TensorFlow and Keras libraries
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, Flatten, Dropout, Dense,
    GlobalAveragePooling2D, BatchNormalization
)
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetV2B0, MobileNetV2
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

print(f'TensorFlow version: {tf.__version__}')

"""## Data Preparation

Link dataset: https://drive.google.com/file/d/1m9UBYCzLElZ8x_-b_jysE7A9y-jSq04u/view?usp=drive_link

### Data Loading
"""

file_id = '1m9UBYCzLElZ8x_-b_jysE7A9y-jSq04u'

# URL untuk mendownload file
url = f'https://drive.google.com/uc?id={file_id}'

# Path untuk menyimpan file
output = '/content/dataset-flowers.zip'

# Mendownload file
gdown.download(url, output, quiet=False)

!unzip dataset-flowers.zip -d dataset-flowers/

def count_images_and_resolution(base_path, target_resolution=None):
    # Dictionary untuk menyimpan jumlah gambar per kelas
    class_count = {}

    # Dictionary untuk menyimpan jumlah gambar per resolusi
    resolution_count = {}

    for root, dirs, files in os.walk(base_path):
        # Mengabaikan folder root yang tidak memiliki gambar
        if root == base_path:
            continue
        class_name = os.path.basename(root)
        class_count[class_name] = len(files)

        for file in files:
            file_path = os.path.join(root, file)
            # Check if the file is an image file
            if not file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                continue # Skip if not an image file
            with Image.open(file_path) as img:
                width, height = img.size
                resolution = f"{width}x{height}"
                if resolution not in resolution_count:
                    resolution_count[resolution] = 0
                resolution_count[resolution] += 1

                # Menghitung jumlah gambar dengan resolusi target_resolution
                if target_resolution and resolution == target_resolution:
                    if 'target' not in resolution_count:
                        resolution_count['target'] = 0
                    resolution_count['target'] += 1

    return class_count, resolution_count

# Path ke folder utama
base_path = "/content/dataset-flowers"

# Resolusi yang ingin dihitung
target_resolution = "256x256"

class_count, resolution_count = count_images_and_resolution(base_path, target_resolution)

# Menampilkan hasil
print("Jumlah gambar per kelas:")
for class_name, count in class_count.items():
    print(f"{class_name}: {count}")

print("\nJumlah gambar per resolusi:")
for resolution, count in resolution_count.items():
    print(f"{resolution}: {count}")

"""terlihat bahwa dataset memiliki berbagai image resolution"""

#Create Files_Name
image_data='/content/dataset-flowers/train'
pd.DataFrame(os.listdir(image_data),columns=['Files_Name'])

#Create Files_Name
image_test_data='/content/dataset-flowers/val'
pd.DataFrame(os.listdir(image_test_data),columns=['Files_Name'])

files = [i for i in glob.glob(image_data + "//*//*")]
np.random.shuffle(files)
labels = [os.path.dirname(i).split("/")[-1] for i in files]
data = zip(files, labels)
dataframe = pd.DataFrame(data, columns = ["Image", "Label"])
dataframe

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x = dataframe["Label"])
plt.xticks(rotation = 90);

"""### Data Preprocessing

#### Split Dataset
"""

train_data_dir =image_data
batch_size = 32
target_size = (224,224)
validation_split = 0.2
train= tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    validation_split=validation_split,
    subset="training",
    seed=100,
    image_size=target_size,
    batch_size=batch_size,
)
validation= tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    validation_split=validation_split,
    subset="validation",
    seed=200,
    image_size=target_size,
    batch_size=batch_size,
)

class_names = train.class_names
class_names

plt.figure(figsize=(15, 20))
for images, labels in train.take(1):
    for i in range(8):
        ax = plt.subplot(8, 4, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i]])
        plt.axis("off")

"""## Modelling"""

base_model = tf.keras.applications.MobileNetV3Large(input_shape=(224,224,3), include_top=False, weights='imagenet')
base_model.trainable = False

keras_model = tf.keras.models.Sequential()

# Add Input layer
keras_model.add(tf.keras.Input(shape=(224,224,3)))

# Add base model (MobileNetV3Large)
keras_model.add(base_model)

# Add custom layers: Conv2D and MaxPooling2D
keras_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same'))  # 64 filters, 3x3 kernel, add padding
keras_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))         # Max Pooling with 2x2 pool size

keras_model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu',padding='same')) # 128 filters, 3x3 kernel, add padding
keras_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))         # Max Pooling with 2x2 pool size

# Flatten and add Dense layers
keras_model.add(tf.keras.layers.Flatten())
keras_model.add(tf.keras.layers.Dropout(0.5))
keras_model.add(tf.keras.layers.Dense(14, activation=tf.nn.softmax))

# Print model summary
keras_model.summary()

tf.keras.utils.plot_model(keras_model, to_file='model.png', show_shapes=True, show_layer_names=True,show_dtype=True,dpi=80)

"""Implementasi Callback"""

checkpoint = ModelCheckpoint("my_keras_model.keras", save_best_only=True) # Change the file extension to .keras

early_stopping =EarlyStopping(patience=5, restore_best_weights=True)

keras_model.compile(optimizer ='Adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# Use fit instead of fit_generator
hist=keras_model.fit(train,epochs=40,validation_data=validation,callbacks=[checkpoint,early_stopping])

hist_=pd.DataFrame(hist.history)
hist_

from matplotlib import pyplot as plt
hist_['accuracy'].plot(kind='line', figsize=(8, 4), title='accuracy')
plt.gca().spines[['top', 'right']].set_visible(False)

"""## Evaluasi dan Visualisasi"""

score, acc = keras_model.evaluate(validation)
print('Test Loss =', score)
print('Test Accuracy =', acc)

plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
plt.plot(hist_['loss'],label='Train_Loss')
plt.plot(hist_['val_loss'],label='Validation_Loss')
plt.title('Train_Loss & Validation_Loss',fontsize=20)
plt.legend()
plt.subplot(1,2,2)
plt.plot(hist_['accuracy'],label='Train_Accuracy')
plt.plot(hist_['val_accuracy'],label='Validation_Accuracy')
plt.title('Train_Accuracy & Validation_Accuracy',fontsize=20)
plt.legend()

"""## Konversi Model

convert model menjadi format .h5
"""

keras_model.save("model.h5")

"""# Konversi TFJS <br>
convert model menjadi format TFJS
"""

!tensorflowjs_converter --input_format=keras model.h5 tfjs_model

"""# Konversi TFLite <br>
convert model menjadi format saved_model
"""

# Menyimpan model TFLITE
model_TFLITE = tf.keras.models.load_model('model.h5')
converter = tf.lite.TFLiteConverter.from_keras_model(model_TFLITE)
tflite_model = converter.convert()

# Buat direktori tflite jika belum ada
import os
os.makedirs('tflite', exist_ok=True)

# Simpan model TFLite
with open('tflite/model.tflite', 'wb') as f:
    f.write(tflite_model)

# Simpan label.txt
class_names = ['astilbe', 'bellflower', 'black_eyed_susan', 'calendula', 'california_poppy',
                'carnation', 'common_daisy', 'coreopsis', 'dandelion', 'iris',
                'rose', 'sunflower', 'tulip', 'water_lily']

with open('tflite/label.txt', 'w') as f:
    for name in class_names:
        f.write(name + '\n')

"""# Konversi SavedModel <br>
convert model menjadi format saved_model
"""

# Menyimpan model SavedModel
save_path = 'saved_model'
tf.saved_model.save(model_TFLITE, save_path)

!pip freeze > requirements.txt

"""## Inference (Optional)"""

from google.colab import files
uploaded = files.upload()

# Dapatkan nama file yang di-upload
uploaded_file_name = list(uploaded.keys())[0]
print(f"Uploaded file name: {uploaded_file_name}")

class_names

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image

# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path="/content/tflite/model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Prepare the image
img_path = '6105173_d0b6a55d9e_c.jpg'
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = img_array.astype('float32')

# Set the tensor to the image
interpreter.set_tensor(input_details[0]['index'], img_array)

# Run inference
interpreter.invoke()

# Get the output
output_data = interpreter.get_tensor(output_details[0]['index'])
predicted_class = np.argmax(output_data, axis=1)

print(f'Predicted class: {class_names[predicted_class[0]]}')

# Display the image and the prediction
plt.imshow(img)
plt.title(f'Predicted: {class_names[predicted_class[0]]}')
plt.axis('off')
plt.show()

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image

# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path="/content/tflite/model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Prepare the image
img_path = '87166799_aabc23303a_c.jpg'
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = img_array.astype('float32')

# Set the tensor to the image
interpreter.set_tensor(input_details[0]['index'], img_array)

# Run inference
interpreter.invoke()

# Get the output
output_data = interpreter.get_tensor(output_details[0]['index'])
predicted_class = np.argmax(output_data, axis=1)

print(f'Predicted class: {class_names[predicted_class[0]]}')

# Display the image and the prediction
plt.imshow(img)
plt.title(f'Predicted: {class_names[predicted_class[0]]}')
plt.axis('off')
plt.show()

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image

# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path="/content/tflite/model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Prepare the image
img_path = '68963342_5e9ba27107_c.jpg'
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = img_array.astype('float32')

# Set the tensor to the image
interpreter.set_tensor(input_details[0]['index'], img_array)

# Run inference
interpreter.invoke()

# Get the output
output_data = interpreter.get_tensor(output_details[0]['index'])
predicted_class = np.argmax(output_data, axis=1)

print(f'Predicted class: {class_names[predicted_class[0]]}')

# Display the image and the prediction
plt.imshow(img)
plt.title(f'Predicted: {class_names[predicted_class[0]]}')
plt.axis('off')
plt.show()